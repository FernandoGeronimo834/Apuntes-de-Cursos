{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f086ce5",
   "metadata": {},
   "source": [
    "# Curso: Introducción a la importación de datos en Python\n",
    "\n",
    "\n",
    "## Leer un archivo de texto (**`.txt`**)\n",
    "\n",
    "\n",
    "Para verificar cualquier archivo de texto sin formato, puede usar la función de apertura básica de Python para abri una conexión con el archivo.\n",
    "\n",
    "Para hacerlo, asigna el nombre del archivo a una varibale como una cadena, pasa el nombre del archiovo a la función open y también le pasa el modo de argumento es igual a **`'r'`**, lo que asegura que solo podamos leerlo (no nos gustarias escribirlo accidentalmente.), asgine el texto del archivo a un texto variable aplicando el métodod e lectura a la conexión con el archivo.\n",
    "\n",
    "Después de hacer esto, asegúrese de cerrar la conexión con el archivo usando el comando `file.close()`. Luego puede imprimir el archivo en la consola y verificarlo usando el comando `print(text)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c623026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filename = './datasets/seaslug.txt'\n",
    "\n",
    "file = open(filename, mode = 'r')\n",
    "\n",
    "text = file.read()\n",
    "\n",
    "print(text)\n",
    "\n",
    "file.close()  # Cerrar siempre el archivo luego de terminar de manipularlo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781042c8",
   "metadata": {},
   "source": [
    "## Escribir en un archivo\n",
    "\n",
    "Si quisieras abrir un archivo en orden para escribirle, le pasaría el modo de argumento igual a **`'w'`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de749a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './datasets/seaslug.txt'\n",
    "\n",
    "file = open(filename, mode = 'w')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec765e",
   "metadata": {},
   "source": [
    "\n",
    "## Administrador de contexto `with`\n",
    "\n",
    "\n",
    "Puede evitar tener que cerrar la conexión con el archivo utilizando una sentencia `with`. Esto le permite crear un contexto en el que puede ejecutar comandos con el archivo abierto. Una vez fuera de esta cláusula/contexto, el archivo ya no está abierto y, por este motivo, se denomina Administrador de contexto.\n",
    "\n",
    "\n",
    "Lo que está haciendo aquí se llama \"vincular\" una variable en la construcción del administrador de contexto; mientras aún esté dentro de esta construcción, el archivo variable estará vinculado a `open(filename, 'r')`.\n",
    "\n",
    "Es una buena practica usar la declaración `with` ya que nunca tendrá que preocuparse por cerrar los archivos nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eff7a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuerde el alma dormida\n",
      "Avive el seso y despierte\n",
      "Contemplando\n",
      "CÃ³mo se pasa la vida,\n",
      "CÃ³mo se viene la muerte,\n",
      "Tan callando,\n",
      "CuÃ¡n presto se va el placer,\n",
      "CÃ³mo, despuÃ©s de acordado\n",
      "Da dolor,\n",
      "CÃ³mo, a nuestro parecer,\n",
      "Cualquier tiempo pasado\n",
      "Fue mejor.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./datasets/seaslug.txt', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bcc32f",
   "metadata": {},
   "source": [
    "# La importancia de los archivos planos en la ciencia de datos\n",
    "\n",
    "\n",
    "## Archivos planos\n",
    "\n",
    "Ahora que sabe cómo importar archivos de texto sin formato, vamos a ver archivos planos, como \"titanic.csv\", en el que cada fil es un pasajero único a bordo y la columna es una caracteristica del atributo, como género, cabina y \"sobrevivió o no\".\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Los archivos planos son archivos de texto básico que contienen registros, es decir, datos de tabla, sin relaciones estructuradas. Esto contrasta con una base de datos relacional, por ejemplo, en la que se pueden relacionar columnas de tablas distintas. Para ser aún más precisos, los archivos planos consisten en registros, donde un registro se refiere a una fila de campos o atributos, cada uno de los cuales contiene como máximo un elemento de información.\n",
    "\n",
    "## Header\n",
    "\n",
    "También es esencial tener en cuenta que un archivo plano pueda tener un encabezado, como en el \"titanic.csv\", que es una fila que ocurre como la primera fila, y describe el contenido de las columnas de datos o establecer cuáles son los atributos o características correspondientes en cada columnas.\n",
    "\n",
    "Será importante saber si su archivo tiene o no un encabezado, ya que puede alterar la importación de datos.\n",
    "\n",
    "La razón por la que los archivos planos son tan importantes en la ciencia de datos es que a los cientificos de datos realmente les gusta pensar en registris o filas de atributos.\n",
    "\n",
    "\n",
    "## Extensión del archivo\n",
    "\n",
    "Ahora es posible que haya notado que la extensión del archivo es `.csv`. CSV es un acrónimo de valor separado por comas y significa exactamente lo que dice. Los valores de cada fila están separados por comas.\n",
    "\n",
    "\n",
    "Otra extensión común para un archivo plano es `.txt`, lo que significa un archivo de texto. Los valores en archivos sin formato se pueden separar por caracteres o secuencias de caracteres distintos que las comas, como un tabulador, y el carácter o caracteres en cuestión se denomina **delimitador**.\n",
    "\n",
    "\n",
    "\n",
    "## Archivo delimitado por tabulador\n",
    "\n",
    "\n",
    "Vea aquí un ejemplo de un archivo delimitado por tabuladores. Los datos consisten en el famoso reconodimiento de dígitos MNIST imagenes, donde cada fila contiene los valores de píxeles de una imagen determinada. \n",
    "\n",
    "Tenga en cuenta que todos los campos en los datos MNIST son numéricos mientras que en el \"titanic.csv\" también contenía cadenas.\n",
    "\n",
    "<img src=\".\\img_3\\1.png\" width=\"350px\" height=\"350px\">\n",
    "\n",
    "<img src=\".\\img_3\\2.png\" width=\"150px\" height=\"350px\">\n",
    "\n",
    "\n",
    "## Como importamos estos archivos?\n",
    "\n",
    "Si consiste completamente en números y queremos almacenarlos como una matriz numpy, podríamos usar numpy.\n",
    "\n",
    "Si, en cambio, queremos almacenar los datos en un marco de datos (DataFrame), podríamos usar pandas.\n",
    "\n",
    "La mayoria de las veces, utilizará una de estas opciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e83a6",
   "metadata": {},
   "source": [
    "# Importación de archivos planos usando NumPy\n",
    "\n",
    "\n",
    "¿Qué sucede si ahora desea importar un archivo plano y asignarlo a una variable?\n",
    "\n",
    "Si todos los datos son numéricos, puede usar el paquete numpy para importar los datos como una matriz numpy.\n",
    "\n",
    "¿Por qué querriamos hacer esto?\n",
    "\n",
    "## ¿Por qué Numpy?\n",
    "\n",
    "En primero lugar, las matrices numpy son el estándar de Python para almacenar datos numéricos. Son eficientes, rápidos y limpios.\n",
    "\n",
    "En segundo lugar, las matrices numpy suelen ser esenciales para otros paquetes, comoscikit-learn, un popular paquete de aprendizaje automatico para Python.\n",
    "\n",
    "Numpy en si tiene una serie de funcionalidades integradas que hacen que sea mucho más fácil y eficiente para nosotros importar datos como matrices.\n",
    "\n",
    "\n",
    "Ingrese las funciones Numpy `loadtxt()` y `genfromtxt()`.\n",
    "\n",
    "\n",
    "## Importar archivo planos usando NumPy\n",
    "\n",
    "Para usar cualquiera de estos, primero debemos importar NumPy. Luego llamamos a `loadtxt()` y le pasamos el nombre del archivo como primer argumento, junto con el delimitador, como segundo argumento. Tenga en cuenta que el delimitador predeterminado es cualquier espacio en blanco, por lo que normalmente necesitaremos especificarlo explícitamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a230620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = './datasets/MNIST.txt'\n",
    "\n",
    "data = np.loadtxt(filename, delimiter = ',')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f1a2f",
   "metadata": {},
   "source": [
    "\n",
    "## Personalización de la importación de Numpy\n",
    "\n",
    "Hay una serie de argumentos adicionales que tal vez desee especificar.\n",
    "\n",
    "Si, por ejemplo, sus datos consisten en números y su encabezado tiene cadenas, como en el MNIST datos de dígitos, querrá omitir la primer fila llamando a `loadtxt` con el argumento `skiprows = 1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "400e4712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [2. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [5. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = './datasets/MNIST.txt'\n",
    "\n",
    "data = np.loadtxt(filename, delimiter = ',', skiprows = 1) #skiprows = [1], , usecols= [0,1]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ef9f5",
   "metadata": {},
   "source": [
    "\n",
    "Si solo desea la primera y la tercera columna de los datos, querrá establecer `usecols = [0,2]`.\n",
    "\n",
    "<img src=\".\\img_3\\4.png\" width=\"150px\" height=\"350px\">\n",
    "\n",
    "\n",
    "### Importar matriz compuesta de cadenas\n",
    "\n",
    "También puede importar diferentes tipos de datos en matrices NumPy: por ejemplo, establecer el argumento `dtype = str` garantizará que todas las entradas se importen como cadenas.\n",
    "\n",
    "**`data = np.loadtxt(filename, delimiter = ',', dtype = str)`**\n",
    "\n",
    "\n",
    "## Tipos de datos Mixtos\n",
    "\n",
    "`loadtxt` es excelente para casos básicos, pero tiende a fallar cuando tenemos tipos de datos mixtos, por ejemplo, columnas que consisten en flotadores y columnas que consisten en cadenas, como vimos en el conjunto de datos Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86403e",
   "metadata": {},
   "source": [
    "# Importar archivos planos usando Pandas\n",
    "\n",
    "\n",
    "\n",
    "## Qué necesit un cientifico de datos:\n",
    "\n",
    "Tener \"una estructura de datos etiquetas [bi]dimensionales con columnas de tipos potencialmente diferentes\" en los que puede realizar fácilmente una gran cantiad de cosas de tipo Data Sceincey: manipular, dividr, remodelar, agrupar, unir, fusionar, realizar estadísticas de una manera amigable con los valores faltantes, manejar series de tiempo.\n",
    "\n",
    "La necesitad de tal estructura de datos, entre otras cuestiones, llevó a Wws McKinney a desarrollar la bibilioteca pandas para Python. Nada hablas más del proyecto de pandas que la propia documentación: \"Python durante mucho tiempo ha sido excelente para la recopilación y preparación de datos, pero no tanto para el análisis y modelado de datos. Pandas ayuda a llenar este vacío, permitíendole llevar a cabo todo su análisis de datos y flujo de trabajo en Python sin tener que cambiar a un lenguaje más especifico de dominio como R\".\n",
    "\n",
    "\n",
    "La estructura de datos más relevante para el flujo de trabajo de análisis y manipulación de datos que ofrece pandas es el marco de datos y es el análogo Pythonic del marco de datos de R.\n",
    "\n",
    "\n",
    "\n",
    "## Manipulando DataFrames Con Pandas\n",
    "\n",
    "\n",
    "La manipulación de marco de datos en pandas puede ser útil en todos los pasos del método cientifico de datos, desde el análisis exploratorio de datos hasta la disputa de datos, el preprocesamiento, la construcción de modelos y la visualización. \n",
    "\n",
    "Aquí veremos su gran utilidad en la importación de archivos planos, incluso en la forma en que trata con datos faltantes, comentarios juntos con muchos otros problemas que afectan a los cientificos de datos en funcionamiento. Por todas estas razones, ahora es estándar y la mejor práctica en Data Science para usar pandas para importar archivos planos como DataFrames.\n",
    "\n",
    "\n",
    "\n",
    "## Importar usando Pandas\n",
    "\n",
    "Para usar pandas, primero debe importarlo. Entonces, si deseamos importar un CSV en el caso más básico, todo lo que tenemos que hacer es llamar a la función `read_csv()` y proporciones un solo argumento, el nombre del archivo. Habiendo asignado el DataFrame a una variable, podemos verificar las primeras 5 filas del DataFrame, incluido el encabezado, con el comando `.head()`.\n",
    "\n",
    "Tambien podemos convertir fácilmente el DataFrame en una matriz numpy llamando al atributo `.values` en el DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0face368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    male  22.0      1      0   \n",
       "1            2         1       1  female  38.0      1      0   \n",
       "2            3         1       3  female  26.0      0      0   \n",
       "3            4         1       1  female  35.0      1      0   \n",
       "4            5         0       3    male  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'.\\datasets\\titanic_sub.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d42d7a",
   "metadata": {},
   "source": [
    "Tambien podemos convertir fácilmente el DataFrame en una matriz numpy llamando al atributo `.values` en el DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eca412e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 3, ..., 7.25, nan, 'S'],\n",
       "       [2, 1, 1, ..., 71.2833, 'C85', 'C'],\n",
       "       [3, 1, 3, ..., 7.925, nan, 'S'],\n",
       "       ...,\n",
       "       [889, 0, 3, ..., 23.45, nan, 'S'],\n",
       "       [890, 1, 1, ..., 30.0, 'C148', 'C'],\n",
       "       [891, 0, 3, ..., 7.75, nan, 'Q']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values # Me devuelve un arreglo bidimensional de numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97ba8a",
   "metadata": {},
   "source": [
    "### Argumentos de `read_csv()`\n",
    "\n",
    "Complete **`sep`**(la pandasversión de delim) **`comment`** los **`na_values`** argumentos de pd.read_csv(). **`comment`** toma los caracteres que aparecen después de los comentarios en el archivo, que en este caso es '#'. **`na_values`** toma una lista de cadenas para reconocer como NA/ NaN, en este caso la cadena 'Nothing'. **`sep`** es el argumento donde se declara el delimitador que podria ser `','`, `'\\t'`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30880d4f",
   "metadata": {},
   "source": [
    "# Introducción a otros tipos de archivos\n",
    "\n",
    "\n",
    "## Otros tipos de archivos\n",
    "\n",
    "* **`Hojas de calculo Excel`**\n",
    "* **`Archivos MATLAB`** \n",
    "* **`Archivos SAS`**\n",
    "* **`Archivos Stata`**\n",
    "* **`Archivos HDF5`**\n",
    "\n",
    "Los archivos HDF5 se están convirtiendo en una forma más frecuente de almacenar grandes conjuntos de datos, ya que demostrado por el hecho de que los investigadores de LIGO lo utilizan para almacenar sus datos.\n",
    "\n",
    "\n",
    "## Archivos Decapado\n",
    "\n",
    "Este es un tipo de archivo nativo de Python. El concepto de decapado de un archivo está motivado por lo siguiente: si bien puede ser fácil guardar una matriz numpy o un DataFrame de pandas en un archivo plano, hay muchos otros tiposd e datos, como diccionarios y listas, para loas que no es obvio cómo almacenarlos.\n",
    "\n",
    "\n",
    "Si desea que sus archivos sean legibles por humanos, es posible que desee guardarlos como archivos de texto de una manera inteligente (los JSON, son apropiados para los diccionarios de Python). Sin embargo, si simplemente desea poder importarlos a Python, puede serializarlos. Todo esto significa convertir el objeto en una secuencia de bytes o flujo de bytes.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Importar archivos Decapados\n",
    "\n",
    "\n",
    "Como lo ha hecho antes, al abrir un archivo de este tipo, querrá especificar que es de solo lectura; Tambien quiero especificar que es un archivo binario, lo que significa que es legible por computadora y no por humanos.\n",
    "\n",
    "Para especificar solo lectura y binario, querrá pasar la cadena `'rb'` como segundo argumento de `open()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7ec9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>size</th>\n",
       "      <th>nb_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.95</td>\n",
       "      <td>small</td>\n",
       "      <td>9626901.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.98</td>\n",
       "      <td>small</td>\n",
       "      <td>8710021.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.93</td>\n",
       "      <td>small</td>\n",
       "      <td>9855053.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.89</td>\n",
       "      <td>small</td>\n",
       "      <td>9405464.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.99</td>\n",
       "      <td>small</td>\n",
       "      <td>8094803.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.53</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1703.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.61</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1270.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.63</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1490.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.59</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1580.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.51</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1289.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1014 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date          type  year  avg_price         size     nb_sold\n",
       "0     2015-12-27  conventional  2015       0.95        small  9626901.09\n",
       "1     2015-12-20  conventional  2015       0.98        small  8710021.76\n",
       "2     2015-12-13  conventional  2015       0.93        small  9855053.66\n",
       "3     2015-12-06  conventional  2015       0.89        small  9405464.36\n",
       "4     2015-11-29  conventional  2015       0.99        small  8094803.56\n",
       "...          ...           ...   ...        ...          ...         ...\n",
       "1009  2018-02-04       organic  2018       1.53  extra_large     1703.52\n",
       "1010  2018-01-28       organic  2018       1.61  extra_large     1270.61\n",
       "1011  2018-01-21       organic  2018       1.63  extra_large     1490.02\n",
       "1012  2018-01-14       organic  2018       1.59  extra_large     1580.01\n",
       "1013  2018-01-07       organic  2018       1.51  extra_large     1289.07\n",
       "\n",
       "[1014 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./datasets/avoplotto.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585be80",
   "metadata": {},
   "source": [
    "## Importar Hojas de cálculo Excel\n",
    "\n",
    "\n",
    "Un archivo de Excel generalmente consta de varias hojas. Hay muchas formas de importar archivos Excel y usted use pandas para hacerlo porque produce DataFrame de forma nativa, lo cual es excelente para su práctica como cientifico de datos.\n",
    "\n",
    "## Importar y mostrar lista con los nombres de las hojas\n",
    "\n",
    "Como puede ver en este ejemplo, puede usar la función `ExcelFile()` para asignar un archivo de Excel a una variable de datos.\n",
    "\n",
    "Como un archivo de Excel consta de hojas, lo primero que debe hacer es averiguar cuáles son las hojas. Esto es sencillo con el comado (atributo) `.sheet_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6792f074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worksheet1']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file = './datasets/Earlwood_Air_Data.xls'\n",
    "\n",
    "data = pd.ExcelFile(file)\n",
    "print(data.sheet_names)  # Me muestra los nombres de las diferentes hojas que contiene el archivo Excel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e763c",
   "metadata": {},
   "source": [
    "## Mostrar una hoja en espeficico de un archivo Excel\n",
    "\n",
    "Para luego cargar una hoja en particular como un DataFrame, solo necesita aplicar el método `.parse()` al objeto `data` con un solo argumento, que es el nombre como una cadena o el índice como un flotante de la hoja que desea carga: Pandas es lo suficientemente inteligennte como para saber si le está diciendo el nombre de la hoja o el índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26645997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>EARLWOOD WDR 1h average [°]</th>\n",
       "      <th>EARLWOOD TEMP 1h average [°C]</th>\n",
       "      <th>EARLWOOD WSP 1h average [m/s]</th>\n",
       "      <th>EARLWOOD NO 1h average [pphm]</th>\n",
       "      <th>EARLWOOD NO2 1h average [pphm]</th>\n",
       "      <th>EARLWOOD CO 1h average [ppm]</th>\n",
       "      <th>EARLWOOD OZONE 1h average [pphm]</th>\n",
       "      <th>EARLWOOD OZONE 4h rolling average [pphm]</th>\n",
       "      <th>EARLWOOD PM10 1h average [µg/m³]</th>\n",
       "      <th>EARLWOOD PM2.5 1h average [µg/m³]</th>\n",
       "      <th>EARLWOOD HUMID 1h average [%]</th>\n",
       "      <th>EARLWOOD SD1 1h average [°]</th>\n",
       "      <th>EARLWOOD CO 8h rolling average [ppm]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>01:00</td>\n",
       "      <td>152.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.2</td>\n",
       "      <td>49.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>02:00</td>\n",
       "      <td>134.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>87.2</td>\n",
       "      <td>46.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time  EARLWOOD WDR 1h average [°]  \\\n",
       "0  01/01/2017  01:00                        152.3   \n",
       "1  01/01/2017  02:00                        134.0   \n",
       "\n",
       "   EARLWOOD TEMP 1h average [°C]  EARLWOOD WSP 1h average [m/s]  \\\n",
       "0                           22.6                            0.4   \n",
       "1                           22.6                            0.3   \n",
       "\n",
       "   EARLWOOD NO 1h average [pphm]  EARLWOOD NO2 1h average [pphm]  \\\n",
       "0                            0.0                             0.4   \n",
       "1                            NaN                             NaN   \n",
       "\n",
       "   EARLWOOD CO 1h average [ppm]  EARLWOOD OZONE 1h average [pphm]  \\\n",
       "0                           NaN                               2.0   \n",
       "1                           NaN                               NaN   \n",
       "\n",
       "   EARLWOOD OZONE 4h rolling average [pphm]  EARLWOOD PM10 1h average [µg/m³]  \\\n",
       "0                                       2.1                              23.6   \n",
       "1                                       2.2                              21.0   \n",
       "\n",
       "   EARLWOOD PM2.5 1h average [µg/m³]  EARLWOOD HUMID 1h average [%]  \\\n",
       "0                                7.0                           87.2   \n",
       "1                                6.6                           87.2   \n",
       "\n",
       "   EARLWOOD SD1 1h average [°]  EARLWOOD CO 8h rolling average [ppm]  \n",
       "0                        49.01                                   NaN  \n",
       "1                        46.56                                   NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = data.parse('worksheet1')  # Usando el nombre de la hoja como String\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb23cfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>EARLWOOD WDR 1h average [°]</th>\n",
       "      <th>EARLWOOD TEMP 1h average [°C]</th>\n",
       "      <th>EARLWOOD WSP 1h average [m/s]</th>\n",
       "      <th>EARLWOOD NO 1h average [pphm]</th>\n",
       "      <th>EARLWOOD NO2 1h average [pphm]</th>\n",
       "      <th>EARLWOOD CO 1h average [ppm]</th>\n",
       "      <th>EARLWOOD OZONE 1h average [pphm]</th>\n",
       "      <th>EARLWOOD OZONE 4h rolling average [pphm]</th>\n",
       "      <th>EARLWOOD PM10 1h average [µg/m³]</th>\n",
       "      <th>EARLWOOD PM2.5 1h average [µg/m³]</th>\n",
       "      <th>EARLWOOD HUMID 1h average [%]</th>\n",
       "      <th>EARLWOOD SD1 1h average [°]</th>\n",
       "      <th>EARLWOOD CO 8h rolling average [ppm]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>01:00</td>\n",
       "      <td>152.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.2</td>\n",
       "      <td>49.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>02:00</td>\n",
       "      <td>134.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>87.2</td>\n",
       "      <td>46.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time  EARLWOOD WDR 1h average [°]  \\\n",
       "0  01/01/2017  01:00                        152.3   \n",
       "1  01/01/2017  02:00                        134.0   \n",
       "\n",
       "   EARLWOOD TEMP 1h average [°C]  EARLWOOD WSP 1h average [m/s]  \\\n",
       "0                           22.6                            0.4   \n",
       "1                           22.6                            0.3   \n",
       "\n",
       "   EARLWOOD NO 1h average [pphm]  EARLWOOD NO2 1h average [pphm]  \\\n",
       "0                            0.0                             0.4   \n",
       "1                            NaN                             NaN   \n",
       "\n",
       "   EARLWOOD CO 1h average [ppm]  EARLWOOD OZONE 1h average [pphm]  \\\n",
       "0                           NaN                               2.0   \n",
       "1                           NaN                               NaN   \n",
       "\n",
       "   EARLWOOD OZONE 4h rolling average [pphm]  EARLWOOD PM10 1h average [µg/m³]  \\\n",
       "0                                       2.1                              23.6   \n",
       "1                                       2.2                              21.0   \n",
       "\n",
       "   EARLWOOD PM2.5 1h average [µg/m³]  EARLWOOD HUMID 1h average [%]  \\\n",
       "0                                7.0                           87.2   \n",
       "1                                6.6                           87.2   \n",
       "\n",
       "   EARLWOOD SD1 1h average [°]  EARLWOOD CO 8h rolling average [ppm]  \n",
       "0                        49.01                                   NaN  \n",
       "1                        46.56                                   NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = data.parse(0)  # Usando el índice de la hoja, (inicia en 0 como en una lista)\n",
    "\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a63c11",
   "metadata": {},
   "source": [
    "# Importación de archivos SAS/Stata usando pandas\n",
    "\n",
    "Existen muchos paquetes de software estadístico y, aunque es posible que no necesite hacerlo todo el tiempo. Será importante para usted, como cienfico de datos en activo, poder importar estos archivos a su entorno de Python.\n",
    "\n",
    "\n",
    "## Archivos SAS y Stata\n",
    "\n",
    "\n",
    "Los ejemplo más comunes son SAS, que es un acrónimo de \"Statistical Analysis System\" y Stata, es una contracción de \"Statistics\" y \"Data\".\n",
    "\n",
    "El primero se usa mucho en análisis de negocios y bioestadística, mientras que este último es popular en la investigación académica de la ciencias sociales, como la economia y la epidemiología.\n",
    "\n",
    "\n",
    "## Archivos SAS\n",
    "\n",
    "Los archivos SAS son importante porque SAs es un paquete de software que realiza analítica avanada, análisis multivariante, inteligencia empresarial, gestión de datos, análisis predictivo y es un estándar para que los estadísticos realicen análisis computacional.\n",
    "\n",
    "\n",
    "## Importar un Archivo SAS\n",
    "\n",
    "Los archivos SAS más comunes tiene la extensión `.sas7bdat` y `.sas7bcat`, que son archivos de conjunto de datos y archivos de catálogos respectivamente.\n",
    "\n",
    "Aprendera a importar los primeros como DataFrame usando la función `SAS7BDAT` del paquete `sas7bdat`.\n",
    "\n",
    "En este caso, puede vincular el archivo de variables a una conexión con el archivo \"sales.sas7bdat\" en un administrador de contexto. Dentro de este contexto, puede asignar a una variable df_sas el resultado de aplicar el método `.to_data_frame` al archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50ffde5e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "source": [
    "pip install sas7bdat  # Instalar libreria SAS7BDAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "518d0893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>P</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>181.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>245.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>250.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>265.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>248.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR     P           S\n",
       "0  1950.0  12.9  181.899994\n",
       "1  1951.0  11.9  245.000000\n",
       "2  1952.0  10.7  250.199997\n",
       "3  1953.0  11.3  265.899994\n",
       "4  1954.0  11.2  248.500000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "with SAS7BDAT('./datasets/sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "\n",
    "df_sas.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4463d827",
   "metadata": {},
   "source": [
    "# Importar Archivos Stata\n",
    "\n",
    "\n",
    "Los archivos Stata tienen extensión `.dta` y podemos importarlos usando pandas. Simplemente pasamos el nombre del archivo a la función `read_stata` y lo asignamos a una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "390a6f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wbcode</th>\n",
       "      <th>country</th>\n",
       "      <th>disa1</th>\n",
       "      <th>disa2</th>\n",
       "      <th>disa3</th>\n",
       "      <th>disa4</th>\n",
       "      <th>disa5</th>\n",
       "      <th>disa6</th>\n",
       "      <th>disa7</th>\n",
       "      <th>disa8</th>\n",
       "      <th>...</th>\n",
       "      <th>disa16</th>\n",
       "      <th>disa17</th>\n",
       "      <th>disa18</th>\n",
       "      <th>disa19</th>\n",
       "      <th>disa20</th>\n",
       "      <th>disa21</th>\n",
       "      <th>disa22</th>\n",
       "      <th>disa23</th>\n",
       "      <th>disa24</th>\n",
       "      <th>disa25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  wbcode               country  disa1  disa2  disa3  disa4  disa5  disa6  \\\n",
       "0    AFG           Afghanistan   0.00   0.00   0.76   0.73    0.0   0.00   \n",
       "1    AGO                Angola   0.32   0.02   0.56   0.00    0.0   0.00   \n",
       "2    ALB               Albania   0.00   0.00   0.02   0.00    0.0   0.00   \n",
       "3    ARE  United Arab Emirates   0.00   0.00   0.00   0.00    0.0   0.00   \n",
       "4    ARG             Argentina   0.00   0.24   0.24   0.00    0.0   0.23   \n",
       "\n",
       "   disa7  disa8  ...  disa16  disa17  disa18  disa19  disa20  disa21  disa22  \\\n",
       "0   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "1   0.56    0.0  ...     0.0     0.4     0.0    0.61    0.00     0.0    0.99   \n",
       "2   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "3   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "4   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.05     0.0    0.00   \n",
       "\n",
       "   disa23  disa24  disa25  \n",
       "0    0.02    0.00    0.00  \n",
       "1    0.98    0.61    0.00  \n",
       "2    0.00    0.00    0.16  \n",
       "3    0.00    0.00    0.00  \n",
       "4    0.01    0.00    0.11  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_stata('./datasets/disarea.dta')\n",
    "\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
