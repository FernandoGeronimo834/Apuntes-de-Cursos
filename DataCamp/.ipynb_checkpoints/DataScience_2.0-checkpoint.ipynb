{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f086ce5",
   "metadata": {},
   "source": [
    "# Curso: Introducción a la importación de datos en Python\n",
    "\n",
    "\n",
    "## Leer un archivo de texto (**`.txt`**)\n",
    "\n",
    "\n",
    "Para verificar cualquier archivo de texto sin formato, puede usar la función de apertura básica de Python para abri una conexión con el archivo.\n",
    "\n",
    "Para hacerlo, asigna el nombre del archivo a una varibale como una cadena, pasa el nombre del archiovo a la función open y también le pasa el modo de argumento es igual a **`'r'`**, lo que asegura que solo podamos leerlo (no nos gustarias escribirlo accidentalmente.), asgine el texto del archivo a un texto variable aplicando el métodod e lectura a la conexión con el archivo.\n",
    "\n",
    "Después de hacer esto, asegúrese de cerrar la conexión con el archivo usando el comando `file.close()`. Luego puede imprimir el archivo en la consola y verificarlo usando el comando `print(text)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c623026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filename = './datasets/seaslug.txt'\n",
    "\n",
    "file = open(filename, mode = 'r')\n",
    "\n",
    "text = file.read()\n",
    "\n",
    "print(text)\n",
    "\n",
    "file.close()  # Cerrar siempre el archivo luego de terminar de manipularlo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781042c8",
   "metadata": {},
   "source": [
    "## Escribir en un archivo\n",
    "\n",
    "Si quisieras abrir un archivo en orden para escribirle, le pasaría el modo de argumento igual a **`'w'`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de749a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './datasets/seaslug.txt'\n",
    "\n",
    "file = open(filename, mode = 'w')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec765e",
   "metadata": {},
   "source": [
    "\n",
    "## Administrador de contexto `with`\n",
    "\n",
    "\n",
    "Puede evitar tener que cerrar la conexión con el archivo utilizando una sentencia `with`. Esto le permite crear un contexto en el que puede ejecutar comandos con el archivo abierto. Una vez fuera de esta cláusula/contexto, el archivo ya no está abierto y, por este motivo, se denomina Administrador de contexto.\n",
    "\n",
    "\n",
    "Lo que está haciendo aquí se llama \"vincular\" una variable en la construcción del administrador de contexto; mientras aún esté dentro de esta construcción, el archivo variable estará vinculado a `open(filename, 'r')`.\n",
    "\n",
    "Es una buena practica usar la declaración `with` ya que nunca tendrá que preocuparse por cerrar los archivos nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eff7a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuerde el alma dormida\n",
      "Avive el seso y despierte\n",
      "Contemplando\n",
      "CÃ³mo se pasa la vida,\n",
      "CÃ³mo se viene la muerte,\n",
      "Tan callando,\n",
      "CuÃ¡n presto se va el placer,\n",
      "CÃ³mo, despuÃ©s de acordado\n",
      "Da dolor,\n",
      "CÃ³mo, a nuestro parecer,\n",
      "Cualquier tiempo pasado\n",
      "Fue mejor.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./datasets/seaslug.txt', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bcc32f",
   "metadata": {},
   "source": [
    "# La importancia de los archivos planos en la ciencia de datos\n",
    "\n",
    "\n",
    "## Archivos planos\n",
    "\n",
    "Ahora que sabe cómo importar archivos de texto sin formato, vamos a ver archivos planos, como \"titanic.csv\", en el que cada fil es un pasajero único a bordo y la columna es una caracteristica del atributo, como género, cabina y \"sobrevivió o no\".\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Los archivos planos son archivos de texto básico que contienen registros, es decir, datos de tabla, sin relaciones estructuradas. Esto contrasta con una base de datos relacional, por ejemplo, en la que se pueden relacionar columnas de tablas distintas. Para ser aún más precisos, los archivos planos consisten en registros, donde un registro se refiere a una fila de campos o atributos, cada uno de los cuales contiene como máximo un elemento de información.\n",
    "\n",
    "## Header\n",
    "\n",
    "También es esencial tener en cuenta que un archivo plano pueda tener un encabezado, como en el \"titanic.csv\", que es una fila que ocurre como la primera fila, y describe el contenido de las columnas de datos o establecer cuáles son los atributos o características correspondientes en cada columnas.\n",
    "\n",
    "Será importante saber si su archivo tiene o no un encabezado, ya que puede alterar la importación de datos.\n",
    "\n",
    "La razón por la que los archivos planos son tan importantes en la ciencia de datos es que a los cientificos de datos realmente les gusta pensar en registris o filas de atributos.\n",
    "\n",
    "\n",
    "## Extensión del archivo\n",
    "\n",
    "Ahora es posible que haya notado que la extensión del archivo es `.csv`. CSV es un acrónimo de valor separado por comas y significa exactamente lo que dice. Los valores de cada fila están separados por comas.\n",
    "\n",
    "\n",
    "Otra extensión común para un archivo plano es `.txt`, lo que significa un archivo de texto. Los valores en archivos sin formato se pueden separar por caracteres o secuencias de caracteres distintos que las comas, como un tabulador, y el carácter o caracteres en cuestión se denomina **delimitador**.\n",
    "\n",
    "\n",
    "\n",
    "## Archivo delimitado por tabulador\n",
    "\n",
    "\n",
    "Vea aquí un ejemplo de un archivo delimitado por tabuladores. Los datos consisten en el famoso reconodimiento de dígitos MNIST imagenes, donde cada fila contiene los valores de píxeles de una imagen determinada. \n",
    "\n",
    "Tenga en cuenta que todos los campos en los datos MNIST son numéricos mientras que en el \"titanic.csv\" también contenía cadenas.\n",
    "\n",
    "<img src=\".\\img_3\\1.png\" width=\"350px\" height=\"350px\">\n",
    "\n",
    "<img src=\".\\img_3\\2.png\" width=\"150px\" height=\"350px\">\n",
    "\n",
    "\n",
    "## Como importamos estos archivos?\n",
    "\n",
    "Si consiste completamente en números y queremos almacenarlos como una matriz numpy, podríamos usar numpy.\n",
    "\n",
    "Si, en cambio, queremos almacenar los datos en un marco de datos (DataFrame), podríamos usar pandas.\n",
    "\n",
    "La mayoria de las veces, utilizará una de estas opciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e83a6",
   "metadata": {},
   "source": [
    "# Importación de archivos planos usando NumPy\n",
    "\n",
    "\n",
    "¿Qué sucede si ahora desea importar un archivo plano y asignarlo a una variable?\n",
    "\n",
    "Si todos los datos son numéricos, puede usar el paquete numpy para importar los datos como una matriz numpy.\n",
    "\n",
    "¿Por qué querriamos hacer esto?\n",
    "\n",
    "## ¿Por qué Numpy?\n",
    "\n",
    "En primero lugar, las matrices numpy son el estándar de Python para almacenar datos numéricos. Son eficientes, rápidos y limpios.\n",
    "\n",
    "En segundo lugar, las matrices numpy suelen ser esenciales para otros paquetes, comoscikit-learn, un popular paquete de aprendizaje automatico para Python.\n",
    "\n",
    "Numpy en si tiene una serie de funcionalidades integradas que hacen que sea mucho más fácil y eficiente para nosotros importar datos como matrices.\n",
    "\n",
    "\n",
    "Ingrese las funciones Numpy `loadtxt()` y `genfromtxt()`.\n",
    "\n",
    "\n",
    "## Importar archivo planos usando NumPy\n",
    "\n",
    "Para usar cualquiera de estos, primero debemos importar NumPy. Luego llamamos a `loadtxt()` y le pasamos el nombre del archivo como primer argumento, junto con el delimitador, como segundo argumento. Tenga en cuenta que el delimitador predeterminado es cualquier espacio en blanco, por lo que normalmente necesitaremos especificarlo explícitamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a230620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = './datasets/MNIST.txt'\n",
    "\n",
    "data = np.loadtxt(filename, delimiter = ',')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f1a2f",
   "metadata": {},
   "source": [
    "\n",
    "## Personalización de la importación de Numpy\n",
    "\n",
    "Hay una serie de argumentos adicionales que tal vez desee especificar.\n",
    "\n",
    "Si, por ejemplo, sus datos consisten en números y su encabezado tiene cadenas, como en el MNIST datos de dígitos, querrá omitir la primer fila llamando a `loadtxt` con el argumento `skiprows = 1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "400e4712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [2. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [5. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = './datasets/MNIST.txt'\n",
    "\n",
    "data = np.loadtxt(filename, delimiter = ',', skiprows = 1) #skiprows = [1], , usecols= [0,1]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ef9f5",
   "metadata": {},
   "source": [
    "\n",
    "Si solo desea la primera y la tercera columna de los datos, querrá establecer `usecols = [0,2]`.\n",
    "\n",
    "<img src=\".\\img_3\\4.png\" width=\"150px\" height=\"350px\">\n",
    "\n",
    "\n",
    "### Importar matriz compuesta de cadenas\n",
    "\n",
    "También puede importar diferentes tipos de datos en matrices NumPy: por ejemplo, establecer el argumento `dtype = str` garantizará que todas las entradas se importen como cadenas.\n",
    "\n",
    "**`data = np.loadtxt(filename, delimiter = ',', dtype = str)`**\n",
    "\n",
    "\n",
    "## Tipos de datos Mixtos\n",
    "\n",
    "`loadtxt` es excelente para casos básicos, pero tiende a fallar cuando tenemos tipos de datos mixtos, por ejemplo, columnas que consisten en flotadores y columnas que consisten en cadenas, como vimos en el conjunto de datos Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86403e",
   "metadata": {},
   "source": [
    "# Importar archivos planos usando Pandas\n",
    "\n",
    "\n",
    "\n",
    "## Qué necesit un cientifico de datos:\n",
    "\n",
    "Tener \"una estructura de datos etiquetas [bi]dimensionales con columnas de tipos potencialmente diferentes\" en los que puede realizar fácilmente una gran cantiad de cosas de tipo Data Sceincey: manipular, dividr, remodelar, agrupar, unir, fusionar, realizar estadísticas de una manera amigable con los valores faltantes, manejar series de tiempo.\n",
    "\n",
    "La necesitad de tal estructura de datos, entre otras cuestiones, llevó a Wws McKinney a desarrollar la bibilioteca pandas para Python. Nada hablas más del proyecto de pandas que la propia documentación: \"Python durante mucho tiempo ha sido excelente para la recopilación y preparación de datos, pero no tanto para el análisis y modelado de datos. Pandas ayuda a llenar este vacío, permitíendole llevar a cabo todo su análisis de datos y flujo de trabajo en Python sin tener que cambiar a un lenguaje más especifico de dominio como R\".\n",
    "\n",
    "\n",
    "La estructura de datos más relevante para el flujo de trabajo de análisis y manipulación de datos que ofrece pandas es el marco de datos y es el análogo Pythonic del marco de datos de R.\n",
    "\n",
    "\n",
    "\n",
    "## Manipulando DataFrames Con Pandas\n",
    "\n",
    "\n",
    "La manipulación de marco de datos en pandas puede ser útil en todos los pasos del método cientifico de datos, desde el análisis exploratorio de datos hasta la disputa de datos, el preprocesamiento, la construcción de modelos y la visualización. \n",
    "\n",
    "Aquí veremos su gran utilidad en la importación de archivos planos, incluso en la forma en que trata con datos faltantes, comentarios juntos con muchos otros problemas que afectan a los cientificos de datos en funcionamiento. Por todas estas razones, ahora es estándar y la mejor práctica en Data Science para usar pandas para importar archivos planos como DataFrames.\n",
    "\n",
    "\n",
    "\n",
    "## Importar usando Pandas\n",
    "\n",
    "Para usar pandas, primero debe importarlo. Entonces, si deseamos importar un CSV en el caso más básico, todo lo que tenemos que hacer es llamar a la función `read_csv()` y proporciones un solo argumento, el nombre del archivo. Habiendo asignado el DataFrame a una variable, podemos verificar las primeras 5 filas del DataFrame, incluido el encabezado, con el comando `.head()`.\n",
    "\n",
    "Tambien podemos convertir fácilmente el DataFrame en una matriz numpy llamando al atributo `.values` en el DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0face368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    male  22.0      1      0   \n",
       "1            2         1       1  female  38.0      1      0   \n",
       "2            3         1       3  female  26.0      0      0   \n",
       "3            4         1       1  female  35.0      1      0   \n",
       "4            5         0       3    male  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'.\\datasets\\titanic_sub.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d42d7a",
   "metadata": {},
   "source": [
    "Tambien podemos convertir fácilmente el DataFrame en una matriz numpy llamando al atributo `.values` en el DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eca412e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 3, ..., 7.25, nan, 'S'],\n",
       "       [2, 1, 1, ..., 71.2833, 'C85', 'C'],\n",
       "       [3, 1, 3, ..., 7.925, nan, 'S'],\n",
       "       ...,\n",
       "       [889, 0, 3, ..., 23.45, nan, 'S'],\n",
       "       [890, 1, 1, ..., 30.0, 'C148', 'C'],\n",
       "       [891, 0, 3, ..., 7.75, nan, 'Q']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values # Me devuelve un arreglo bidimensional de numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97ba8a",
   "metadata": {},
   "source": [
    "### Argumentos de `read_csv()`\n",
    "\n",
    "Complete **`sep`**(la pandasversión de delim) **`comment`** los **`na_values`** argumentos de pd.read_csv(). **`comment`** toma los caracteres que aparecen después de los comentarios en el archivo, que en este caso es '#'. **`na_values`** toma una lista de cadenas para reconocer como NA/ NaN, en este caso la cadena 'Nothing'. **`sep`** es el argumento donde se declara el delimitador que podria ser `','`, `'\\t'`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30880d4f",
   "metadata": {},
   "source": [
    "# Introducción a otros tipos de archivos\n",
    "\n",
    "\n",
    "## Otros tipos de archivos\n",
    "\n",
    "* **`Hojas de calculo Excel`**\n",
    "* **`Archivos MATLAB`** \n",
    "* **`Archivos SAS`**\n",
    "* **`Archivos Stata`**\n",
    "* **`Archivos HDF5`**\n",
    "\n",
    "Los archivos HDF5 se están convirtiendo en una forma más frecuente de almacenar grandes conjuntos de datos, ya que demostrado por el hecho de que los investigadores de LIGO lo utilizan para almacenar sus datos.\n",
    "\n",
    "\n",
    "## Archivos Decapado\n",
    "\n",
    "Este es un tipo de archivo nativo de Python. El concepto de decapado de un archivo está motivado por lo siguiente: si bien puede ser fácil guardar una matriz numpy o un DataFrame de pandas en un archivo plano, hay muchos otros tiposd e datos, como diccionarios y listas, para loas que no es obvio cómo almacenarlos.\n",
    "\n",
    "\n",
    "Si desea que sus archivos sean legibles por humanos, es posible que desee guardarlos como archivos de texto de una manera inteligente (los JSON, son apropiados para los diccionarios de Python). Sin embargo, si simplemente desea poder importarlos a Python, puede serializarlos. Todo esto significa convertir el objeto en una secuencia de bytes o flujo de bytes.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Importar archivos Decapados\n",
    "\n",
    "\n",
    "Como lo ha hecho antes, al abrir un archivo de este tipo, querrá especificar que es de solo lectura; Tambien quiero especificar que es un archivo binario, lo que significa que es legible por computadora y no por humanos.\n",
    "\n",
    "Para especificar solo lectura y binario, querrá pasar la cadena `'rb'` como segundo argumento de `open()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7ec9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>size</th>\n",
       "      <th>nb_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.95</td>\n",
       "      <td>small</td>\n",
       "      <td>9626901.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.98</td>\n",
       "      <td>small</td>\n",
       "      <td>8710021.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.93</td>\n",
       "      <td>small</td>\n",
       "      <td>9855053.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.89</td>\n",
       "      <td>small</td>\n",
       "      <td>9405464.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.99</td>\n",
       "      <td>small</td>\n",
       "      <td>8094803.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.53</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1703.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.61</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1270.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.63</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1490.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.59</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1580.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.51</td>\n",
       "      <td>extra_large</td>\n",
       "      <td>1289.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1014 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date          type  year  avg_price         size     nb_sold\n",
       "0     2015-12-27  conventional  2015       0.95        small  9626901.09\n",
       "1     2015-12-20  conventional  2015       0.98        small  8710021.76\n",
       "2     2015-12-13  conventional  2015       0.93        small  9855053.66\n",
       "3     2015-12-06  conventional  2015       0.89        small  9405464.36\n",
       "4     2015-11-29  conventional  2015       0.99        small  8094803.56\n",
       "...          ...           ...   ...        ...          ...         ...\n",
       "1009  2018-02-04       organic  2018       1.53  extra_large     1703.52\n",
       "1010  2018-01-28       organic  2018       1.61  extra_large     1270.61\n",
       "1011  2018-01-21       organic  2018       1.63  extra_large     1490.02\n",
       "1012  2018-01-14       organic  2018       1.59  extra_large     1580.01\n",
       "1013  2018-01-07       organic  2018       1.51  extra_large     1289.07\n",
       "\n",
       "[1014 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./datasets/avoplotto.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585be80",
   "metadata": {},
   "source": [
    "## Importar Hojas de cálculo Excel\n",
    "\n",
    "\n",
    "Un archivo de Excel generalmente consta de varias hojas. Hay muchas formas de importar archivos Excel y usted use pandas para hacerlo porque produce DataFrame de forma nativa, lo cual es excelente para su práctica como cientifico de datos.\n",
    "\n",
    "## Importar y mostrar lista con los nombres de las hojas\n",
    "\n",
    "Como puede ver en este ejemplo, puede usar la función `ExcelFile()` para asignar un archivo de Excel a una variable de datos.\n",
    "\n",
    "Como un archivo de Excel consta de hojas, lo primero que debe hacer es averiguar cuáles son las hojas. Esto es sencillo con el comado (atributo) `.sheet_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6792f074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worksheet1']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file = './datasets/Earlwood_Air_Data.xls'\n",
    "\n",
    "data = pd.ExcelFile(file)\n",
    "print(data.sheet_names)  # Me muestra los nombres de las diferentes hojas que contiene el archivo Excel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e763c",
   "metadata": {},
   "source": [
    "## Mostrar una hoja en espeficico de un archivo Excel\n",
    "\n",
    "Para luego cargar una hoja en particular como un DataFrame, solo necesita aplicar el método `.parse()` al objeto `data` con un solo argumento, que es el nombre como una cadena o el índice como un flotante de la hoja que desea carga: Pandas es lo suficientemente inteligennte como para saber si le está diciendo el nombre de la hoja o el índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26645997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>EARLWOOD WDR 1h average [°]</th>\n",
       "      <th>EARLWOOD TEMP 1h average [°C]</th>\n",
       "      <th>EARLWOOD WSP 1h average [m/s]</th>\n",
       "      <th>EARLWOOD NO 1h average [pphm]</th>\n",
       "      <th>EARLWOOD NO2 1h average [pphm]</th>\n",
       "      <th>EARLWOOD CO 1h average [ppm]</th>\n",
       "      <th>EARLWOOD OZONE 1h average [pphm]</th>\n",
       "      <th>EARLWOOD OZONE 4h rolling average [pphm]</th>\n",
       "      <th>EARLWOOD PM10 1h average [µg/m³]</th>\n",
       "      <th>EARLWOOD PM2.5 1h average [µg/m³]</th>\n",
       "      <th>EARLWOOD HUMID 1h average [%]</th>\n",
       "      <th>EARLWOOD SD1 1h average [°]</th>\n",
       "      <th>EARLWOOD CO 8h rolling average [ppm]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>01:00</td>\n",
       "      <td>152.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.2</td>\n",
       "      <td>49.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>02:00</td>\n",
       "      <td>134.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>87.2</td>\n",
       "      <td>46.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time  EARLWOOD WDR 1h average [°]  \\\n",
       "0  01/01/2017  01:00                        152.3   \n",
       "1  01/01/2017  02:00                        134.0   \n",
       "\n",
       "   EARLWOOD TEMP 1h average [°C]  EARLWOOD WSP 1h average [m/s]  \\\n",
       "0                           22.6                            0.4   \n",
       "1                           22.6                            0.3   \n",
       "\n",
       "   EARLWOOD NO 1h average [pphm]  EARLWOOD NO2 1h average [pphm]  \\\n",
       "0                            0.0                             0.4   \n",
       "1                            NaN                             NaN   \n",
       "\n",
       "   EARLWOOD CO 1h average [ppm]  EARLWOOD OZONE 1h average [pphm]  \\\n",
       "0                           NaN                               2.0   \n",
       "1                           NaN                               NaN   \n",
       "\n",
       "   EARLWOOD OZONE 4h rolling average [pphm]  EARLWOOD PM10 1h average [µg/m³]  \\\n",
       "0                                       2.1                              23.6   \n",
       "1                                       2.2                              21.0   \n",
       "\n",
       "   EARLWOOD PM2.5 1h average [µg/m³]  EARLWOOD HUMID 1h average [%]  \\\n",
       "0                                7.0                           87.2   \n",
       "1                                6.6                           87.2   \n",
       "\n",
       "   EARLWOOD SD1 1h average [°]  EARLWOOD CO 8h rolling average [ppm]  \n",
       "0                        49.01                                   NaN  \n",
       "1                        46.56                                   NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = data.parse('worksheet1')  # Usando el nombre de la hoja como String\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb23cfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>EARLWOOD WDR 1h average [°]</th>\n",
       "      <th>EARLWOOD TEMP 1h average [°C]</th>\n",
       "      <th>EARLWOOD WSP 1h average [m/s]</th>\n",
       "      <th>EARLWOOD NO 1h average [pphm]</th>\n",
       "      <th>EARLWOOD NO2 1h average [pphm]</th>\n",
       "      <th>EARLWOOD CO 1h average [ppm]</th>\n",
       "      <th>EARLWOOD OZONE 1h average [pphm]</th>\n",
       "      <th>EARLWOOD OZONE 4h rolling average [pphm]</th>\n",
       "      <th>EARLWOOD PM10 1h average [µg/m³]</th>\n",
       "      <th>EARLWOOD PM2.5 1h average [µg/m³]</th>\n",
       "      <th>EARLWOOD HUMID 1h average [%]</th>\n",
       "      <th>EARLWOOD SD1 1h average [°]</th>\n",
       "      <th>EARLWOOD CO 8h rolling average [ppm]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>01:00</td>\n",
       "      <td>152.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.2</td>\n",
       "      <td>49.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>02:00</td>\n",
       "      <td>134.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>87.2</td>\n",
       "      <td>46.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time  EARLWOOD WDR 1h average [°]  \\\n",
       "0  01/01/2017  01:00                        152.3   \n",
       "1  01/01/2017  02:00                        134.0   \n",
       "\n",
       "   EARLWOOD TEMP 1h average [°C]  EARLWOOD WSP 1h average [m/s]  \\\n",
       "0                           22.6                            0.4   \n",
       "1                           22.6                            0.3   \n",
       "\n",
       "   EARLWOOD NO 1h average [pphm]  EARLWOOD NO2 1h average [pphm]  \\\n",
       "0                            0.0                             0.4   \n",
       "1                            NaN                             NaN   \n",
       "\n",
       "   EARLWOOD CO 1h average [ppm]  EARLWOOD OZONE 1h average [pphm]  \\\n",
       "0                           NaN                               2.0   \n",
       "1                           NaN                               NaN   \n",
       "\n",
       "   EARLWOOD OZONE 4h rolling average [pphm]  EARLWOOD PM10 1h average [µg/m³]  \\\n",
       "0                                       2.1                              23.6   \n",
       "1                                       2.2                              21.0   \n",
       "\n",
       "   EARLWOOD PM2.5 1h average [µg/m³]  EARLWOOD HUMID 1h average [%]  \\\n",
       "0                                7.0                           87.2   \n",
       "1                                6.6                           87.2   \n",
       "\n",
       "   EARLWOOD SD1 1h average [°]  EARLWOOD CO 8h rolling average [ppm]  \n",
       "0                        49.01                                   NaN  \n",
       "1                        46.56                                   NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = data.parse(0)  # Usando el índice de la hoja, (inicia en 0 como en una lista)\n",
    "\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a63c11",
   "metadata": {},
   "source": [
    "# Importación de archivos SAS/Stata usando pandas\n",
    "\n",
    "Existen muchos paquetes de software estadístico y, aunque es posible que no necesite hacerlo todo el tiempo. Será importante para usted, como cienfico de datos en activo, poder importar estos archivos a su entorno de Python.\n",
    "\n",
    "\n",
    "## Archivos SAS y Stata\n",
    "\n",
    "\n",
    "Los ejemplo más comunes son SAS, que es un acrónimo de \"Statistical Analysis System\" y Stata, es una contracción de \"Statistics\" y \"Data\".\n",
    "\n",
    "El primero se usa mucho en análisis de negocios y bioestadística, mientras que este último es popular en la investigación académica de la ciencias sociales, como la economia y la epidemiología.\n",
    "\n",
    "\n",
    "## Archivos SAS\n",
    "\n",
    "Los archivos SAS son importante porque SAs es un paquete de software que realiza analítica avanada, análisis multivariante, inteligencia empresarial, gestión de datos, análisis predictivo y es un estándar para que los estadísticos realicen análisis computacional.\n",
    "\n",
    "\n",
    "## Importar un Archivo SAS\n",
    "\n",
    "Los archivos SAS más comunes tiene la extensión `.sas7bdat` y `.sas7bcat`, que son archivos de conjunto de datos y archivos de catálogos respectivamente.\n",
    "\n",
    "Aprendera a importar los primeros como DataFrame usando la función `SAS7BDAT` del paquete `sas7bdat`.\n",
    "\n",
    "En este caso, puede vincular el archivo de variables a una conexión con el archivo \"sales.sas7bdat\" en un administrador de contexto. Dentro de este contexto, puede asignar a una variable df_sas el resultado de aplicar el método `.to_data_frame` al archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50ffde5e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "source": [
    "pip install sas7bdat  # Instalar libreria SAS7BDAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "518d0893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>P</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>181.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>245.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>250.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>265.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>248.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR     P           S\n",
       "0  1950.0  12.9  181.899994\n",
       "1  1951.0  11.9  245.000000\n",
       "2  1952.0  10.7  250.199997\n",
       "3  1953.0  11.3  265.899994\n",
       "4  1954.0  11.2  248.500000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "with SAS7BDAT('./datasets/sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "\n",
    "df_sas.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4463d827",
   "metadata": {},
   "source": [
    "# Importar Archivos Stata\n",
    "\n",
    "\n",
    "Los archivos Stata tienen extensión `.dta` y podemos importarlos usando pandas. Simplemente pasamos el nombre del archivo a la función `read_stata` y lo asignamos a una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "390a6f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wbcode</th>\n",
       "      <th>country</th>\n",
       "      <th>disa1</th>\n",
       "      <th>disa2</th>\n",
       "      <th>disa3</th>\n",
       "      <th>disa4</th>\n",
       "      <th>disa5</th>\n",
       "      <th>disa6</th>\n",
       "      <th>disa7</th>\n",
       "      <th>disa8</th>\n",
       "      <th>...</th>\n",
       "      <th>disa16</th>\n",
       "      <th>disa17</th>\n",
       "      <th>disa18</th>\n",
       "      <th>disa19</th>\n",
       "      <th>disa20</th>\n",
       "      <th>disa21</th>\n",
       "      <th>disa22</th>\n",
       "      <th>disa23</th>\n",
       "      <th>disa24</th>\n",
       "      <th>disa25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  wbcode               country  disa1  disa2  disa3  disa4  disa5  disa6  \\\n",
       "0    AFG           Afghanistan   0.00   0.00   0.76   0.73    0.0   0.00   \n",
       "1    AGO                Angola   0.32   0.02   0.56   0.00    0.0   0.00   \n",
       "2    ALB               Albania   0.00   0.00   0.02   0.00    0.0   0.00   \n",
       "3    ARE  United Arab Emirates   0.00   0.00   0.00   0.00    0.0   0.00   \n",
       "4    ARG             Argentina   0.00   0.24   0.24   0.00    0.0   0.23   \n",
       "\n",
       "   disa7  disa8  ...  disa16  disa17  disa18  disa19  disa20  disa21  disa22  \\\n",
       "0   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "1   0.56    0.0  ...     0.0     0.4     0.0    0.61    0.00     0.0    0.99   \n",
       "2   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "3   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "4   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.05     0.0    0.00   \n",
       "\n",
       "   disa23  disa24  disa25  \n",
       "0    0.02    0.00    0.00  \n",
       "1    0.98    0.61    0.00  \n",
       "2    0.00    0.00    0.16  \n",
       "3    0.00    0.00    0.00  \n",
       "4    0.01    0.00    0.11  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_stata('./datasets/disarea.dta')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020bdb6c",
   "metadata": {},
   "source": [
    "# Importación de archivos HDF5\n",
    "\n",
    " \n",
    "##  Archivos HDF5\n",
    "\n",
    "En el mundo de Python, el consenso está convergiendo rápidamente en la versión de formato de datos jerárquicos 5, o \"HDF5\", como el mecanismo estándar para almacenar grandes cantidades de datos numéricos.\n",
    "\n",
    "\n",
    "* **De qué tamaño estamos hablando aquí?**\n",
    "\n",
    "\n",
    "Ahora es relativamente común tratar con conjuntos de datos de cientos de gigabytes o inclusos terabytes de tamaño; HDF5 en sí mismo puede escalar hasta exabytes.\n",
    "\n",
    "\n",
    "\n",
    "Exploremos con un ejemplo concreto de LIGO, el proyecto del Observatorio de ondas gravitacionales con interferómetro láser.\n",
    "\n",
    "\n",
    "## Importar Archivo HDF5\n",
    "\n",
    "\n",
    "Primero importar el paquete h5py y luego importar el archivo usando `h5py.File()`, recordando usar `\"r\"` para especificar solo lectura. \n",
    "\n",
    "Imprimir el tipo de datos revela que estamos tratando con un archivo `h5py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d26d3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.files.File'>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "filename = './datasets/L-L1_LOSC_4_V1-1126259446-32.hdf5'\n",
    "\n",
    "data = h5py.File(filename, 'r') # 'r' es para leer\n",
    "\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00640586",
   "metadata": {},
   "source": [
    "## La estructura del Archivo HDF5\n",
    "\n",
    "\n",
    "Pero, ¿cuál es la estructura de este archivo?\n",
    "\n",
    "Puede explorar su estructura jerárquica como lo haría con un diccionario de Python usando el método de `.keys()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf522f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta\n",
      "quality\n",
      "strain\n"
     ]
    }
   ],
   "source": [
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa739c",
   "metadata": {},
   "source": [
    "Ves que hay tres claves, meta, calidad y tensión. Cada uno de estos es un grupo HDF. Puede pensar en estos grupos como diccionarios.\n",
    "\n",
    "La documentación de LIGO nos dice que 'meta' contiene metadatos para el archivo, 'calidad' contiene información sobre la calidad de los datos y 'tensión' contiene 'datos de tensión del inferómetro', la principal medida realizada por LIGO, los datos de interés. \n",
    "\n",
    "Si supiera qué datos y metadatos deberían estar en cada grupo, podría acceder a ellos directamente. Sin embargo, si no, debido a la naturaleza jerárquica de la estructura de archivos, es fácil de explorar.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "Digamos que desea averiguar qué tipo de metadatos hay, podría imprimir fácilmente las claves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbdca443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description\n",
      "DescriptionURL\n",
      "Detector\n",
      "Duration\n",
      "GPSstart\n",
      "Observatory\n",
      "Type\n",
      "UTCstart\n"
     ]
    }
   ],
   "source": [
    "for key in data['meta'].keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4205f",
   "metadata": {},
   "source": [
    "Ahora que conoce las claves, puede acceder a cualquier metadato de su interés. Si está interesado en 'Description' y 'Detector', puede pasar estas claves para la función `np.array()` para convertir los valores en una matriz Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b07a3a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Strain data time series from LIGO' b'L1'\n"
     ]
    }
   ],
   "source": [
    "print(np.array(data['meta']['Description']),  np.array(data['meta']['Detector']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b4de9",
   "metadata": {},
   "source": [
    "Verá que los datos en el archivo son \"Serie temporal de datos de tensión de LIGO\" y que el detector utilizado fue \"L1\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9bcc28",
   "metadata": {},
   "source": [
    "# Importación de Archivos MATLAB\n",
    "\n",
    "\n",
    "MATLAB, que significa Matrix Laboratory, es un ambiente de computación numérica que es un estándar de la industria en las disciplinas de la ingenieria y la ciencia. Esto se debe en parte a sus poderosas capacidades de matriz y álgebra lineal, en parte a su naturaleza propietaria y en parte a lo difícil que le resulta al mundo académico deshacerse de los viejo hábitos.\n",
    "\n",
    "Independientemente de las razones de su uso generalizado, el hecho es que una gran cantidad de la gente usa MATLAB y guarda sus datos como archivos `.mat`, el formato de archivo nativo de MATLAB. \n",
    "\n",
    "* **¿Cómo puedes importarlos a Python?\n",
    "\n",
    "Afortunadamente para nosotros, la biblioteca estándar `scipy` tiene funciones `loadmat` y `savemat`, que nos permite leer y escribir archivos `.mat`, respectivamente.\n",
    "\n",
    "\n",
    "## Qué hay en un archivo `.mat`?\n",
    "\n",
    "* **¿Qué hay exactamente en un archivo `.mat`?**\n",
    "\n",
    "Para responder esto, veamos el IDE de MATLAB.\n",
    "\n",
    "En particular, consulte el espacio de trabajo de MATLAB donde se almacenan todas sus variables. Este espacio de trabajo puede contener cadenas, flotantes, vectores y matrices, entre muchos otros objetos.\n",
    "\n",
    "Un archivo `.mat` es simplemente una colección de dicho objetos.\n",
    "\n",
    "## Importar un archivo `.mat`\n",
    "\n",
    "Ahora bien, esto significa que al importar un archivo `.mat` en Python, debe esperar ver una serie de diferentes variables y objetos.\n",
    "\n",
    "En este código, primero importo `scipy.io` y luego cargo el archivo `ja_data2.mat`. Verificar qué tipo de objeto da como resultado me dice que es un diccionario.\n",
    "\n",
    "La forma en que este diccionario se relaciona con un espacio de trabajo e MATLAB es sencilla: Las claves del diccionario de Python son los nombres de las variables de MATLAB y los valores del diccionario de Python son los objetos que se asignan a las variables.\n",
    "\n",
    "* **Llaves:** Nombre de variables de MATLAB.\n",
    "\n",
    "* **Valores:** Objetos que se le asignan a las variables.\n",
    "\n",
    "En el ejemplo anterior,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6af2f0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "filename = './datasets/ja_data2.mat'\n",
    "\n",
    "mat = scipy.io.loadmat(filename)\n",
    "\n",
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caa115a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Tue Nov 24 17:35:19 2015', '__version__': '1.0', '__globals__': [], 'rfpCyt': array([[  0.        , 238.62933333, 238.62264151, ..., 250.17403315,\n",
      "        249.05801105, 251.3489011 ],\n",
      "       [  0.        , 291.7718254 , 292.006     , ..., 269.99239544,\n",
      "        271.32044199, 271.26086957],\n",
      "       [  0.        , 252.45212766, 253.34851138, ..., 225.76428571,\n",
      "        224.02909091, 226.38103757],\n",
      "       ...,\n",
      "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 373.45756458, 377.05420561, ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 415.25079365,   0.        , ..., 407.76514032,\n",
      "        402.54331865, 409.40528634]]), 'rfpNuc': array([[  0.        , 183.34256055, 187.84859155, ..., 200.62101911,\n",
      "        198.79566563, 201.73566879],\n",
      "       [  0.        , 191.7195122 , 189.11340206, ..., 183.73829787,\n",
      "        187.35918367, 189.04320988],\n",
      "       [  0.        , 174.97307692, 174.79961464, ..., 157.78478664,\n",
      "        157.32887189, 157.59962049],\n",
      "       ...,\n",
      "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 247.48251748, 249.63270142, ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 280.50465839,   0.        , ..., 249.66157761,\n",
      "        247.85316456, 250.16287879]]), 'cfpNuc': array([[  0.        , 844.75086505, 874.15492958, ..., 710.70382166,\n",
      "        715.50154799, 727.59872611],\n",
      "       [  0.        , 643.34878049, 641.84020619, ..., 583.27021277,\n",
      "        603.84897959, 608.45679012],\n",
      "       [  0.        , 487.2       , 486.08863198, ..., 435.80705009,\n",
      "        431.29063098, 439.29222011],\n",
      "       ...,\n",
      "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 535.31235431, 541.69194313, ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 793.31832298,   0.        , ..., 584.53435115,\n",
      "        577.9835443 , 599.96085859]]), 'cfpCyt': array([[   0.        , 1519.37866667, 1518.73045822, ..., 1354.96132597,\n",
      "        1352.75966851, 1367.18681319],\n",
      "       [   0.        , 1175.74007937, 1176.164     , ..., 1098.57984791,\n",
      "        1109.05893186, 1111.66847826],\n",
      "       [   0.        ,  856.7535461 ,  856.88091068, ...,  736.54821429,\n",
      "         738.08909091,  746.82110912],\n",
      "       ...,\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [   0.        ,  908.85424354,  920.44859813, ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [   0.        , 1256.34603175,    0.        , ..., 1128.29542097,\n",
      "        1122.6328928 , 1170.41703377]]), 'yfpNuc': array([[  0.        , 532.3633218 , 551.92253521, ..., 495.13375796,\n",
      "        497.89783282, 507.28025478],\n",
      "       [  0.        , 448.39268293, 448.56958763, ..., 399.82553191,\n",
      "        417.9244898 , 421.81069959],\n",
      "       [  0.        , 307.85576923, 308.32177264, ..., 283.20222635,\n",
      "        281.00382409, 285.47628083],\n",
      "       ...,\n",
      "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 326.36363636, 330.20379147, ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 502.60869565,   0.        , ..., 418.83842239,\n",
      "        417.3721519 , 426.93434343]]), 'yfpCyt': array([[  0.        , 951.432     , 944.48787062, ..., 939.66022099,\n",
      "        936.        , 949.12912088],\n",
      "       [  0.        , 840.49801587, 836.542     , ..., 767.11596958,\n",
      "        781.38489871, 780.76811594],\n",
      "       [  0.        , 578.08865248, 577.66725044, ..., 509.98035714,\n",
      "        512.38181818, 515.31127013],\n",
      "       ...,\n",
      "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 577.48708487, 590.89719626, ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        , 812.01904762,   0.        , ..., 901.44756278,\n",
      "        896.88399413, 920.85756241]]), 'CYratioCyt': array([[0.        , 1.53071547, 1.54297013, ..., 1.34990123, 1.35329984,\n",
      "        1.34922173],\n",
      "       [0.        , 1.28605578, 1.29385656, ..., 1.31307311, 1.30039694,\n",
      "        1.30563938],\n",
      "       [0.        , 1.32731222, 1.32884617, ..., 1.24887565, 1.24506205,\n",
      "        1.25825831],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 1.44552606, 1.42862357, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 1.45794466, 0.        , ..., 1.1229479 , 1.12224652,\n",
      "        1.1486481 ]])}\n"
     ]
    }
   ],
   "source": [
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83e40919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Tue Nov 24 17:35:19 2015' \n",
      "\n",
      "\n",
      "[[0.         1.53071547 1.54297013 ... 1.34990123 1.35329984 1.34922173]\n",
      " [0.         1.28605578 1.29385656 ... 1.31307311 1.30039694 1.30563938]\n",
      " [0.         1.32731222 1.32884617 ... 1.24887565 1.24506205 1.25825831]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         1.44552606 1.42862357 ... 0.         0.         0.        ]\n",
      " [0.         1.45794466 0.         ... 1.1229479  1.12224652 1.1486481 ]]\n"
     ]
    }
   ],
   "source": [
    "print(mat['__header__'], '\\n\\n')\n",
    "\n",
    "\n",
    "print(mat['CYratioCyt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac11b5",
   "metadata": {},
   "source": [
    "# Introducción a las bases de datos relacionales\n",
    "\n",
    "\n",
    "## ¿Qué es una base de datos relacional?\n",
    "\n",
    "Es un tipo de base de datos que se basa en el modelo de datos relacional, descripto por primer vez por Ted Codd a finales de la década de 1960.\n",
    "\n",
    "## Ejemplo: Base de datos Northwind \n",
    "\n",
    "\n",
    "Base de datos de Northwind Traders, una base de datos sntética que contiene datos de ventas de una empresa ficticia.\n",
    "\n",
    "\n",
    "<img src=\".\\img_3\\5.png\" width=\"650px\" height=\"350px\">\n",
    "\n",
    "En primer lugar, una base de datos consta de tablas. Aquí puede ver 3 tablas de la base de datos Northwind: \n",
    "\n",
    "* Ordenes\n",
    "* Clientes\n",
    "* Empleados\n",
    "\n",
    "**Entonces, ¿qué es una tabla?**\n",
    "\n",
    "Una tabla generalmente representa un tipo de entidad. Como \"Orden\"\n",
    "\n",
    "\n",
    "## La tabla de \"ordenes\"\n",
    "\n",
    "<img src=\".\\img_3\\6.png\" width=\"550px\" height=\"350px\">\n",
    "\n",
    "Tenga en cuenta que esta tabla se parece mucho a un DataFrame. Ese es el punto. En una tabla de base de datos relacional, cada fila o registro representa una instancia del tipo de entidad: en este caso, cada fila es una Orden. Cada columna representa un atributo de cada instancia, como \"OrderDate\" en el caso de \"Orders\".\n",
    "\n",
    "En este sentido, una tabla es completamente análoga a un DataFrame. Es esencial que cada fila contenga un identificador único, conocido como `clave principal`, que podemos usar para acceder explícitamente a la fila en cuestión.\n",
    "\n",
    "En nuestra tabla de \"Ordenes\", puede ver que la clave es \"OrderID\" la primera columna. Pero recuerde que una base de datos consta de muchas tablas.\n",
    "\n",
    "Lo realmente genial de las bases de datos relacionales no es simplemente que tienen un mónton de tablas, lo es que las tablas están enlazadas.\n",
    "\n",
    "<img src=\".\\img_3\\7.png\" width=\"550px\" height=\"350px\">\n",
    "\n",
    "Cómo funcionan este enlace es ultra-intuitivo: vea que la tabla de \"Ordenes\" tiene una columna llamada \"CustomerID\" como otra llamada \"EmployeeID\". Estas columnas corresponden precisamente a las claves primaria en las tablas \"Clientes\" y \"Empleados\", respectivamente.\n",
    "\n",
    "Entonces, dado que un Pedido, puede buscar inmediatamente los detalles del Cliente o Empleado relevante. Esto es genial porque significa que no necesita almacenar todos los detalles del Cliente, como el nombre, apellido, empresa con cada pedido que hacer: solo tienes que buscarlo en la tabla \"Clientes\". Esto ahorra una cantidad increible de espacio.\n",
    "\n",
    "\n",
    "\n",
    "## Modelo Relacional\n",
    "\n",
    "\n",
    "Como se indicó anteriormente, el modelo de base de datos relacional fue propuesto originalmente por \"Ted Codd\" y ha sido ampliamente adoptado. Hay mucho en la teoría, pero está más claramente resumido en las 12 reglas de Codd, también conodidas como los 12 Mandamientos de Codd, que desarrolló a principios de 1980 para combatir lo que él veía como una dilución de su visión original de base de datos relacional.\n",
    "\n",
    "Las 12 reglas de Codd en realidad consisten en 13 reglas pero tienen un índice cero, es decir, la primer regla tiene un índice cero.\n",
    "\n",
    "\n",
    "Estas 13 reglas se definieron para describir qué es una base de datos relacional.  \n",
    "\n",
    "El Sistema de Gestión debe cumplir para ser considerado relacional.\n",
    "\n",
    "\n",
    "## Sistemas de gestión de bases de datos relacionales\n",
    "\n",
    "Entre los más populare e tales sistemas están PostgreSQL, Mysql y SQLite, todos los cuales utilizan el lenguaje de consulta SQL. De echo, SQL en sí mismo es en realidad un acrónimo para el lenguaje (Language) de consulta (Query) estructurado (Structured), que describe cómo te comunicas con una base de datos para acceder y actualizar la información que contiene.\n",
    "\n",
    "El término \"Consultad\" es realmente una forma elegante de decir obtener datos de la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f2976",
   "metadata": {},
   "source": [
    "# Creando un motor de base de datos en Python\n",
    "\n",
    "\n",
    "Lo que realmente queremos hacer es obtener datos de nuestra base de datos utilizando SQL o el lenguaje de consulta estructurado.\n",
    "\n",
    "## Crear un motor de base de datos\n",
    "\n",
    "Usaremos una base de datos SQLite como ejemplo porque SQLite es rápido y simple mientras que contien suficiente funcionalidad para presentarle todos los conceptos necesarios para consultar una base de datos.\n",
    "\n",
    "\n",
    "Hay muchos paquetes que podríamos usar para acceder a una base de datos SQLite como sqlite3 y SQLAlchemy.\n",
    "\n",
    "Usaremos SQLAlchemy, ya que funciona con mucho otros sistemas de administración de bases de datos relacionales, como POSTgres y MySQL.\n",
    "\n",
    "\n",
    "Para conectarse a \"Chinook.sqlite\", necesitamos importar la función relevante `create_engine()` del paquete SQLAlchemy.\n",
    "\n",
    "Luego usamos la función `create_engine()` para iniciar un motor SQL que comunicará nuestras consultas a la base de datos. El único argumento requerido de `create_engine()` es una cadena que indica el tipo de base de datos a la que se está conectando y el nombre de la base de datos. A continuación, para consultar la base de datos, debemos conectarnos al motor para hacerlo. Pero antes de hacer esto, nos gustaria saber el nombre de las tablas que contiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c160dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///./datasets/Chinook.sqlite')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6f6c61",
   "metadata": {},
   "source": [
    "## Obtener nombres de las tablas\n",
    "\n",
    "Para ello, aplique el método `table_names()` al motor de objetos. Esto devolverá una lista de los nombre de las tablas que luego puede imprimir en la consola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6193edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fer_s\\AppData\\Local\\Temp\\ipykernel_13368\\865887770.py:1: SADeprecationWarning: The Engine.table_names() method is deprecated and will be removed in a future release.  Please refer to Inspector.get_table_names(). (deprecated since: 1.4)\n",
      "  table_names = engine.table_names()\n"
     ]
    }
   ],
   "source": [
    "table_names = engine.table_names()\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96f354",
   "metadata": {},
   "source": [
    "# Consultando bases de datos relacionales en Python\n",
    "\n",
    "Ahora que ha descubierto cómo crear un motor de base de datos y enumerar las tablas de la base de datos en cuestión, es hora de conectarse al motor y consultar la base de datos.\n",
    "\n",
    "Una vez más, el término \"consultar\" es solo una forma elegante de decir obtener datos de la base de datos.\n",
    "\n",
    "\n",
    "## Consultas basicas de SQL\n",
    "\n",
    "\n",
    "El \"Hola mundo\" de consultas SQL es 'SELECT * FROM Table_Nane', donde 'Table_name' es el nombre de cualquiera de las tablas en la base de datos.\n",
    "\n",
    "Esta consulta devuelve todas las columnas de todas las filas de la tabla de interés.\n",
    "\n",
    "`SELECT * FROM Table_name`\n",
    "\n",
    "Por ejemplo, podría consultar la base de datos Northwind con `SELECT * FROM Orders` y esto devolvería todas la columnas de todas las filas de la tabla \"Ordenes\". El Asterisco (`*`) después de SELECT significa \"todas las columnas\".\n",
    "\n",
    "Esta es una consulta SQL y necesitamos descubrir cómo hacer dicha consulta usando Python, SQLAlchemy y, de hecho, también usaremos pandas para almacenar los resultados de nuestras consultas.\n",
    "\n",
    "## Flujo de trabajo de las consultas SQL\n",
    "\n",
    "El flujo de trabajo será el siguiente:\n",
    "\n",
    "Importara los paquetes y funciones requeridos, creará el motor, se concetará a él, consultara la base de datos, guardara los resultados de la consulta en un DataFrame y cerrara la conexión.\n",
    "\n",
    "\n",
    "* 1) **Importara paquetes y funciones**\n",
    "* 2) **Creará el motor de base de datos**\n",
    "* 3) **Se conectará al motor**\n",
    "* 4) **Consultara la base de datos**\n",
    "* 5) **Guardara los resultados en un DataFrame**\n",
    "* 6) **Cerrara la conexión**\n",
    "\n",
    "\n",
    "## Su primero consulta SQL\n",
    "\n",
    "Cree el motor usando la función `create_engine()`. Para conectarse a la base de datos después de crear el motor, cree un objeto de conexión aplicando el método `.connect()` al motor.\n",
    "\n",
    "Para consultar la base de datos, aplique el método de ejecución a la conexión `con` y pásele un solo argumento, la consulta SQL relevante; Esto creara un objeto de resultado de SQLAlchemy que asignamos a la variable `rs`.\n",
    "\n",
    "Para convertir el objeto de resultado `rs` en un DataFrame, aplicamos el método `fetchall()` a `rs` y guárdelo como un DataFrame usando la función de pandas `.DataFrame()`. `fetchall()` obtiene todas las filas, como era de esperar. \n",
    "\n",
    "Para cerrar la conexión, ejecute `con.close()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3175e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso N° 1\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Paso N° 2\n",
    "engine = create_engine('sqlite:///./datasets/Chinook.sqlite')\n",
    "\n",
    "# Paso N°3\n",
    "con = engine.connect()\n",
    "\n",
    "# Paso N° 4\n",
    "rs = con.execute('SELECT * FROM Album')\n",
    "\n",
    "# Paso N° 5\n",
    "\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "# Paso N° 6\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c449c4",
   "metadata": {},
   "source": [
    "## Imprimir los resultados de la consulta\n",
    "\n",
    "A continuacion puede imprimir el encabezado del DataFrame, como hemos hecho antes, como prueba de cordura: todas las filas se ven bien pero los nombres de las columnas no son correctos (Podria aparecerme con números como en los índices.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd0db18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlbumId</th>\n",
       "      <th>Title</th>\n",
       "      <th>ArtistId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>For Those About To Rock We Salute You</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Balls to the Wall</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Restless and Wild</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Let There Be Rock</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Big Ones</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AlbumId                                  Title  ArtistId\n",
       "0        1  For Those About To Rock We Salute You         1\n",
       "1        2                      Balls to the Wall         2\n",
       "2        3                      Restless and Wild         2\n",
       "3        4                      Let There Be Rock         1\n",
       "4        5                               Big Ones         3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09d414",
   "metadata": {},
   "source": [
    "## Establecer los nombres de las columnas del DataFrame\n",
    "\n",
    "Para solucionar los nombres de las columnas, antes de cerrar conexión, puede configurar los nombre de las columnas del DataFrame ejecutando `df.columns = rs.keys()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11cb96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso N° 1\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Paso N° 2\n",
    "engine = create_engine('sqlite:///./datasets/Chinook.sqlite')\n",
    "\n",
    "# Paso N°3\n",
    "con = engine.connect()\n",
    "\n",
    "# Paso N° 4\n",
    "rs = con.execute('SELECT * FROM Album')\n",
    "\n",
    "# Paso N° 5\n",
    "\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "df.columns = rs.keys()\n",
    "\n",
    "# Paso N° 6\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efc9fd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlbumId</th>\n",
       "      <th>Title</th>\n",
       "      <th>ArtistId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>For Those About To Rock We Salute You</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Balls to the Wall</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Restless and Wild</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Let There Be Rock</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Big Ones</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AlbumId                                  Title  ArtistId\n",
       "0        1  For Those About To Rock We Salute You         1\n",
       "1        2                      Balls to the Wall         2\n",
       "2        3                      Restless and Wild         2\n",
       "3        4                      Let There Be Rock         1\n",
       "4        5                               Big Ones         3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d735bb",
   "metadata": {},
   "source": [
    "## Ejemplo con la tabla 'Artist':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee36e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso N° 1\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Paso N° 2\n",
    "engine = create_engine('sqlite:///./datasets/Chinook.sqlite')\n",
    "\n",
    "# Paso N°3\n",
    "con = engine.connect()\n",
    "\n",
    "# Paso N° 4\n",
    "rs = con.execute('SELECT * FROM Artist')\n",
    "\n",
    "# Paso N° 5\n",
    "\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "df.columns = rs.keys()\n",
    "\n",
    "# Paso N° 6\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f336b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArtistId</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AC/DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aerosmith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alanis Morissette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alice In Chains</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArtistId               Name\n",
       "0         1              AC/DC\n",
       "1         2             Accept\n",
       "2         3          Aerosmith\n",
       "3         4  Alanis Morissette\n",
       "4         5    Alice In Chains"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094dbdd",
   "metadata": {},
   "source": [
    "## Usar un Administrador de contexto\n",
    "\n",
    "Una última nota: de forma análoga a lo que vio anteriormente al abrir archivos de texto sin formato, puede usar la construcción del administrador de contexto para abrir una conexión, lo que le ahorrá el problema de cerra la conexión más tarde, o ahorrarle la molestia de olvidarse de cerrarla. \n",
    "\n",
    "Hay otras dos diferencias que puede haber notados entre este y el código anterior: en primero lugar, ya no tener `SELECT *` en la consulta SQL; ahora tengo nombres de columnas de la tabla \"Ordenes\"; todo lo que hace es importar esas columnas particulares y no otras muesntras que `SELECT *` importa todas las columnas; en segundo lugar, en lugar de aplicar el método `fetchall()` a los resultados `rs`, aplico el método `fetchmany()` con el tamaño del argumento igual a 5; esto importara 5 filas en lugar de todas las filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d497215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forma N° 1\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///./datasets/Chinook.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdda8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forma N° 2\n",
    "\n",
    "with engine.connect() as con:\n",
    "    \n",
    "    rs = con.execute('SELECT AlbumId, Title FROM Album')\n",
    "    \n",
    "    df = pd.DataFrame(rs.fetchmany(size = 5))\n",
    "    \n",
    "    df.columns = rs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c74a0be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlbumId</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>For Those About To Rock We Salute You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Balls to the Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Restless and Wild</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AlbumId                                  Title\n",
       "0        1  For Those About To Rock We Salute You\n",
       "1        2                      Balls to the Wall\n",
       "2        3                      Restless and Wild"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93463f21",
   "metadata": {},
   "source": [
    "# Consultar bases de datos relacionales directamente con pandas\n",
    "\n",
    "Después de crear un motor de base de datos puede obtener los resultados de cualquier línea particular usando 4 líneas de código: conectando, ejecutando una consulta, pasando los resultados a un dataframe y nombrando las columnas: 4 líneas de código es bastante bueno, pero puede hacerlo mejor.\n",
    "\n",
    "## La forma pandas de hacer consultas\n",
    "\n",
    "De hecho, puede hacerlo en 1 línea, utilizando la función pandas `read_sql_query` y pasándole 2 argumentos. \n",
    "\n",
    "El primer argumento será la consulta que desea realizar, el segundo argumento el motor al que desea conectarse. Y, por lo tanto, puede lograr lo mismo que este código ejecutando esta única línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db7c15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forma N° 1\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///./datasets/Chinook.sqlite')\n",
    "\n",
    "# -----------------------------------\n",
    "\n",
    "# Forma N° 2\n",
    "\n",
    "with engine.connect() as con:\n",
    "    \n",
    "    rs = con.execute('SELECT AlbumId, Title FROM Album')\n",
    "    \n",
    "    df = pd.DataFrame(rs.fetchmany(size = 5))\n",
    "    \n",
    "    df.columns = rs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a80d8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query('SELECT * FROM Album', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829127a2",
   "metadata": {},
   "source": [
    "# Consulta avanzada: explotación de las relaciones entre tablas\n",
    "\n",
    "\n",
    "## Las tablas están vinculadas\n",
    "\n",
    "Como vimos anteriormente, la tabla \"Ordenes\" de la base de datos Northwind Traders tiene una columna llamada \"CustomerID\" y una columna llamada \"EmployeeID\", columnas que corresponden precisamente a las claves primarias en las tablas \"Clientes\" y \"Empleados\", respectivamente. Esto significa que, dada una Orden, puede buscar inmediatamente el detalle del Cliente o Empleado relevante en la tabla correspondiente.\n",
    "\n",
    "<img src=\".\\img_3\\8.png\" width=\"550px\" height=\"350px\">\n",
    "\n",
    "\n",
    "## Unir tablas\n",
    "\n",
    "Ahora, ¿qué sucede si desea incorporar dicha información en su consulta?\n",
    "\n",
    "Por ejemplo, si desea consultar la tabla \"Ordenes\" e incluir, para cada Pedido, ¿información sobre el Cliente correspondiente a la tabla \"Cliente?\"\n",
    "\n",
    "Digamos que quería, para cada Orden, obtener el ID de pedido y el CompanyName del Cliente. OrderID vive en la tabla \"Ordenes\" mientras que CompanyName vive en la tabla \"Clientes\".\n",
    "\n",
    "\n",
    "<img src=\".\\img_3\\9.png\" width=\"450px\" height=\"350px\">\n",
    "\n",
    "\n",
    "SQL tiene una manera muy inteligente de hacer esto: se llama JOIN porque lo que realmente estás haciendo es unir dos tablas, en este caso, las tablas de \"Ordenes\" y \"Clientes\". Específicamente es una UNION INTERNA.\n",
    "\n",
    "\n",
    "## INNER JOIN en Python (pandas)\n",
    "\n",
    "\n",
    "Como son las columnas \"CustomerID\" de las tablas \"Ordenes\" y \"Clientes\" las que corresponden a cada una, querrá UNIRSE a las tablas EN estas columnas y eso precisamente lo que hace el siguiente código.\n",
    "\n",
    "La notación de punto seguida de nombre de la columna es simplemente seleccionar una columna de una tabla.\n",
    "\n",
    "La tabla de la que estamos seleccionando es \"Album INNER JOIN Artist on Album.ArtistId = Artist.ArtistId\" y estoy seleccionando la columna AlbumId, Title, y Name de esta nueva tabla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338c919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlbumId</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>For Those About To Rock We Salute You</td>\n",
       "      <td>AC/DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Balls to the Wall</td>\n",
       "      <td>Accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Restless and Wild</td>\n",
       "      <td>Accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Let There Be Rock</td>\n",
       "      <td>AC/DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Big Ones</td>\n",
       "      <td>Aerosmith</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AlbumId                                  Title       Name\n",
       "0        1  For Those About To Rock We Salute You      AC/DC\n",
       "1        2                      Balls to the Wall     Accept\n",
       "2        3                      Restless and Wild     Accept\n",
       "3        4                      Let There Be Rock      AC/DC\n",
       "4        5                               Big Ones  Aerosmith"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///./datasets/Chinook.sqlite')\n",
    "\n",
    "df = pd.read_sql_query('SELECT AlbumId, Title,Name FROM Album INNER JOIN Artist on Album.ArtistId = Artist.ArtistId', engine)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8492c9",
   "metadata": {},
   "source": [
    "# Curso: Intermedio Importar datos en Python\n",
    "\n",
    "\n",
    "# Importación de archivos planos desde la web\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
